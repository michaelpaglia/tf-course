{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJ5F9qY+9wuru8CxOrjl7U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Linear regression:"],"metadata":{"id":"FRmX41-Nc2cs"}},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"em69pPIy2w4u","executionInfo":{"status":"ok","timestamp":1703008952252,"user_tz":300,"elapsed":8749,"user":{"displayName":"M. Joseph","userId":"13843001583923662030"}},"outputId":"95827847-9290-41a6-d33d-aae258b84aa6"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7651515\n"]}],"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","import tensorflow as tf\n","\n","dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n","dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n","y_train = dftrain.pop('survived')\n","y_eval = dfeval.pop('survived')\n","\n","def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n","  def input_function():  # inner function, this will be returned\n","    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n","    if shuffle:\n","      ds = ds.shuffle(1000)  # randomize order of data\n","    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n","    return ds  # return a batch of the dataset\n","  return input_function  # return a function object for use\n","\n","train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n","eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n","\n","linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n","\n","linear_est.train(train_input_fn)  # train\n","result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on tetsing data\n","\n","clear_output()  # clears consoke output\n","print(result['accuracy'])"]},{"cell_type":"code","source":["result = list(linear_est.predict(eval_input_fn))\n","print(result[5]['probabilities'][1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ye1nWbI628Ey","executionInfo":{"status":"ok","timestamp":1703009268797,"user_tz":300,"elapsed":1856,"user":{"displayName":"M. Joseph","userId":"13843001583923662030"}},"outputId":"7cadb5d9-df66-44a6-f60a-748551ce1dc6"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6925876\n"]}]},{"cell_type":"markdown","source":["Classification:"],"metadata":{"id":"xY_vU10PcxAZ"}},{"cell_type":"code","source":["CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n","SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n","\n","train_path = tf.keras.utils.get_file(\n","    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n","test_path = tf.keras.utils.get_file(\n","    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n","\n","train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n","test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n","train_y = train.pop('Species')\n","test_y = test.pop('Species')\n","train.head()\n","\n","def input_fn(features, labels, training=True, batch_size=256):\n","    # Convert the inputs to a Dataset.\n","    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n","\n","    # Shuffle and repeat if you are in training mode.\n","    if training:\n","        dataset = dataset.shuffle(1000).repeat()\n","\n","    return dataset.batch(batch_size)\n","\n","my_feature_columns = []\n","for key in train.keys():\n","    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n","print(my_feature_columns)\n","\n","classifier = tf.estimator.DNNClassifier(\n","    feature_columns=my_feature_columns,\n","    # Two hidden layers of 30 and 10 nodes respectively.\n","    hidden_units=[30, 10],\n","    # The model must choose between 3 classes.\n","    n_classes=3)\n","\n","classifier.train(\n","    input_fn=lambda: input_fn(train, train_y, training=True),\n","    steps=5000)\n","classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-4OEmSTRYoQ","executionInfo":{"status":"ok","timestamp":1703010207655,"user_tz":300,"elapsed":13191,"user":{"displayName":"M. Joseph","userId":"13843001583923662030"}},"outputId":"0c4b9355-8827-4c7b-e71a-ce16f33352c8"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpdeqqv1zu\n"]},{"output_type":"stream","name":"stdout","text":["[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 0.93333334,\n"," 'average_loss': 0.43333092,\n"," 'loss': 0.43333092,\n"," 'global_step': 5000}"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["def input_fn(features, batch_size=256):\n","    # Convert the inputs to a Dataset without labels.\n","    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n","\n","features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n","predict = {}\n","\n","print(\"Please type numeric values as prompted.\")\n","for feature in features:\n","  valid = True\n","  while valid:\n","    val = input(feature + \": \")\n","    if not val.isdigit(): valid = False\n","\n","  predict[feature] = [float(val)]\n","\n","predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n","for pred_dict in predictions:\n","    class_id = pred_dict['class_ids'][0]\n","    probability = pred_dict['probabilities'][class_id]\n","\n","    print('Prediction is \"{}\" ({:.1f}%)'.format(\n","        SPECIES[class_id], 100 * probability))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qe0XFNCLVazA","executionInfo":{"status":"ok","timestamp":1703010550812,"user_tz":300,"elapsed":5580,"user":{"displayName":"M. Joseph","userId":"13843001583923662030"}},"outputId":"36288a90-0824-42d9-a744-6732197a0f4a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Please type numeric values as prompted.\n","SepalLength: 3.5\n","SepalWidth: 3.\n","PetalLength: 3.5\n","PetalWidth: 3.2\n","Prediction is \"Virginica\" (67.3%)\n"]}]},{"cell_type":"markdown","source":["Hidden Markov:"],"metadata":{"id":"-Mn5odHtctES"}},{"cell_type":"code","source":["import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n","import tensorflow as tf\n","\n","tfd = tfp.distributions  # making a shortcut for later on\n","initial_distribution = tfd.Categorical(probs=[0.2, 0.8])  # Refer to point 2 above\n","transition_distribution = tfd.Categorical(probs=[[0.7, 0.3],\n","                                                 [0.2, 0.8]])  # refer to points 3 and 4 above\n","\n","observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.])  # refer to point 5 above\n","# the loc argument represents the mean and the scale is the standard devitation\n","\n","model = tfd.HiddenMarkovModel(\n","    initial_distribution=initial_distribution,\n","    transition_distribution=transition_distribution,\n","    observation_distribution=observation_distribution,\n","    num_steps=7)\n","\n","mean = model.mean()\n","\n","# due to the way TensorFlow works on a lower level we need to evaluate part of the graph\n","# from within a session to see the value of this tensor\n","\n","# in the new version of tensorflow we need to use tf.compat.v1.Session() rather than just tf.Session()\n","with tf.compat.v1.Session() as sess:\n","  print(mean.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mchVs1RtbCSI","executionInfo":{"status":"ok","timestamp":1703012245944,"user_tz":300,"elapsed":2014,"user":{"displayName":"M. Joseph","userId":"13843001583923662030"}},"outputId":"846baaea-eeea-43d6-ae9c-9b5771a0a066"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["[11.999999 10.500001  9.75      9.375     9.1875    9.09375   9.046875]\n"]}]}]}